{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage.measure import label,regionprops\n",
    "from skimage.morphology import binary_opening, erosion, dilation, ball\n",
    "from skimage.segmentation import watershed\n",
    "from scipy import ndimage\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from skimage.morphology import opening, closing, ball\n",
    "from skimage.filters import gaussian\n",
    "import numpy as np\n",
    "import nrrd\n",
    "from skimage.segmentation import morphological_geodesic_active_contour as gac\n",
    "from skimage.segmentation import inverse_gaussian_gradient as igg\n",
    "from scipy.ndimage.morphology import binary_fill_holes\n",
    "from scipy.stats import entropy\n",
    "# from scripts.ImageSliceViewer3D import ImageSliceViewer3D as isv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "SUPPLEMENTARY FUNCTION : createSubVolumes\n",
    "This function isolates the sub-volume of the image that we are interested in. \n",
    "This way, we can perform operations only on the pixels containing lesion and surrounding pixels (executes faster).\n",
    "    \n",
    "    INPUT:\n",
    "            image         - the original CT volume;\n",
    "            image_dict    - dictionary with CT metadata;\n",
    "            mask          - the original mask with radiologist-defined ROIs;\n",
    "            lprop         - regionprops object for the user-defined start point.\n",
    "            \n",
    "    OUTPUT:\n",
    "            cylinder_subV - cylinder mask, which occupies same space as both image and mask sub-volumes;\n",
    "            image_subV    - image sub-volume, which contains lesion plus surrounding voxels;\n",
    "            mask_subV     - ground truth labels, which occupies same space as both image and cylinder sub-volumes;\n",
    "            R             - cylinder radius, for downstream calculations.\n",
    "            \n",
    "'''\n",
    "\n",
    "def createSubVolumes(image,image_dict,mask,lprop):\n",
    "    \n",
    "    # construct cylinder_image\n",
    "    bbox = lprop.bbox  \n",
    "    bbox_dims = [bbox[3]-bbox[0],bbox[4]-bbox[1],bbox[-1]-bbox[2]]\n",
    "    \n",
    "    # take a circle with radius larger than bounding box\n",
    "#   R = bbox_dims[0]/2 + bbox_dims[1]/2  \n",
    "    R = max(bbox_dims)*5/8       \n",
    "    \n",
    "    # isolate the centroid of the nodule -- this will be our preliminary marker \n",
    "    j,i,k = [round(i) for i in lprop.centroid] \n",
    "\n",
    "    circle_mask = np.zeros((image.shape[0],image.shape[1]),dtype=bool)\n",
    "    num_rows,num_cols = circle_mask.shape\n",
    "\n",
    "    row,col = np.meshgrid(range(num_rows),range(num_cols))\n",
    "    circle_mask[((row-i)**2+(col-j)**2)<R**2] = True\n",
    "            \n",
    "    # now we have the initial contour (that will theoretically be user-defined for the clinical dataset)\n",
    "    # next step: extend the circle in both superior and inferior directions to obtain a cylinder\n",
    "\n",
    "    # determine the number of slices required in the z direction for full coverage\n",
    "    num_slices = int(np.ceil((float(image_dict['pixel_spacing']) * R) / float(image_dict['slice_thickness'])/2))\n",
    "\n",
    "    cylinder_image = np.zeros((image.shape[0],image.shape[1],image.shape[2]),dtype=bool)\n",
    "\n",
    "    for i in range(k-num_slices,k+num_slices+1):\n",
    "        cylinder_image[:,:,i] = circle_mask\n",
    "                \n",
    "    # label the mask into connected regions\n",
    "    mask_labels = label(cylinder_image)\n",
    "    mask_props = regionprops(mask_labels)\n",
    "\n",
    "    coords = mask_props[0].bbox\n",
    "\n",
    "    cylinder_subV = mask_props[0].image\n",
    "    image_subV = image[coords[0]:coords[3],coords[1]:coords[4],coords[2]:coords[-1]]\n",
    "    mask_subV = mask[coords[0]:coords[3],coords[1]:coords[4],coords[2]:coords[-1]]\n",
    "    \n",
    "    return cylinder_subV,image_subV,mask_subV,R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3047185591.py, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [3]\u001b[0;36m\u001b[0m\n\u001b[0;31m    expanded_bbox = [coords[0]-row:coords[3]+row,coords[1]-row:coords[4]+row,coords[2]-slc:coords[-1]+slc]\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "SUPPLEMENTARY FUNCTION : createSubVolumesClinical\n",
    "This function isolates the sub-volume of the image that we are interested in. \n",
    "This way, we can perform operations only on the pixels containing lesion and surrounding pixels (executes faster).\n",
    "    \n",
    "    INPUT:\n",
    "            image         - the original CT volume;\n",
    "            image_dict    - dictionary with CT metadata;\n",
    "            mask          - the original mask with radiologist-defined ROIs;\n",
    "            lprop         - regionprops object for the user-defined start point.\n",
    "            \n",
    "    OUTPUT:\n",
    "            image_subV    - image sub-volume, which contains lesion plus surrounding voxels;\n",
    "            mask_subV     - ground truth labels, which occupies same space as both image and cylinder sub-volumes.\n",
    "            \n",
    "'''\n",
    "\n",
    "def createSubVolumesClinical(image,mask,lprop):\n",
    "    \n",
    "    # get the bounding box for the user-defined mask in image coordinates\n",
    "    coords = lprop.bbox \n",
    "    row = 3\n",
    "    slc = 1\n",
    "    \n",
    "    # crop the image and mask to the expanded bounding box\n",
    "    image_subV = image[coords[0]-row:coords[3]+row,coords[1]-row:coords[4]+row,coords[2]-slc:coords[-1]+slc]\n",
    "    mask_subV = mask[coords[0]-row:coords[3]+row,coords[1]-row:coords[4]+row,coords[2]-slc:coords[-1]+slc]\n",
    "    \n",
    "    return image_subV,mask_subV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "SUPPLEMENTARY FUNCTION : determineThreshold\n",
    "This function determines a threshold separating candidate lesion voxels from surrounding lung paremchyma. \n",
    "It leverages the BayesianGaussianMixture functionality from sklearn. \n",
    "Since the pre-defined sub-volume contains both lesion and lung parenchyma pixels, density distribution \n",
    "of the pixels could be modeled by two Gaussian distributions: P(x|lesion) and P(x|parenchyma), \n",
    "where x was the pixel density. The mean values and variations of the two Gaussian distributions were \n",
    "then estimated by the expectation-maximization method.\n",
    "    \n",
    "    INPUT:\n",
    "            image_subV    - the CT sub-volume;\n",
    "            cylinder_subV - cylinder mask occupying the same space as the image_subV.\n",
    "            \n",
    "    OUTPUT:\n",
    "            threshold     - floating point threshold (anything above this threshold is a candidate lesion voxel)\n",
    "                     \n",
    "'''\n",
    "\n",
    "def determineThreshold(image_subV,cylinder_subV):\n",
    "    \n",
    "    # isolate the intensities within the cylinder\n",
    "    intensities = image_subV[cylinder_subV]\n",
    "\n",
    "    hist, bin_edges = np.histogram(intensities, bins=60)\n",
    "    bin_centers = 0.5*(bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "    classif = BayesianGaussianMixture(n_components=2)\n",
    "    classif.fit(intensities.reshape(-1,1))\n",
    "\n",
    "    return np.mean(classif.means_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lists of image/mask files\n",
    "img_path = '/Users/EL-CAPITAN-2016/OneDrive - UHN/SARC/timeseries/semi-automated/Images'\n",
    "msk_path = '/Users/EL-CAPITAN-2016/OneDrive - UHN/SARC/timeseries/semi-automated/Masks'\n",
    "\n",
    "all_images = sorted([os.path.join(img_path,f) for f in os.listdir(img_path) if 'nrrd' in f])\n",
    "all_masks = sorted([os.path.join(msk_path,f) for f in os.listdir(msk_path) if 'nrrd' in f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE:</b>\n",
    "    \n",
    "The `all_images` and `all_masks` variables contain pointers to individual files. The files in these folders are not separated by time point. Take the first four pointers in the `all_images` variable as an example:\n",
    "<br>   \n",
    "`./Images/112001_BL_image.nrrd`,<br>\n",
    "`./Images/112001_C2_image.nrrd`,<br>\n",
    "`./Images/112002_BL_image.nrrd`,<br>\n",
    "`./Images/112002_C2_image.nrrd`,...<br>\n",
    "<br>   \n",
    "The first six digits is the unique subject identifier, and the two letters that follow encode the timepoint, where **BL** is the baseline or first measurement and **C2** is the measurement after 2 cycles of chemotherapy or second measurement.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arm information -- the hypoxia drug is encoded as 1\n",
    "key = pd.read_csv('./trial_arm_key.csv')\n",
    "key.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usubjid,timepoint,fileID = os.path.basename(all_images[2]).split('_')\n",
    "# print(key['ARM'][np.where(key['USUBJID']==str(usubjid))])\n",
    "all_images[4]\n",
    "int(usubjid)\n",
    "# print(key['USUBJID'].dtype)\n",
    "key.loc[key['USUBJID'] == int(usubjid),'ARM'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first pass of segmentation pipeline\n",
    "def segPipeline(imgList,mskList):\n",
    "    \n",
    "    # initialize lists for segmentation accuracy\n",
    "    usubjid = []\n",
    "    timepoint = []\n",
    "    trial_arm = []\n",
    "    lesion_index = []\n",
    "    lesion_volume = []\n",
    "    \n",
    "    for i in range(len(imgList)):\n",
    "        \n",
    "        # read image and corresponding mask\n",
    "        img_V,img_d = nrrd.read(imgList[i])\n",
    "        msk_V,msk_d = nrrd.read(mskList[i])\n",
    "        \n",
    "        patient_id,time_id,fileID = os.path.basename(imgList[i]).split('_')\n",
    "        pixel_volume = float(msk_d['pixel_spacing'])**2 * float(msk_d['slice_thickness']) # in mm^3\n",
    "        \n",
    "        # if the image and mask do not have the same size, do not process\n",
    "        if not (img_d['sizes'] == msk_d['sizes']).all():\n",
    "            print('ERROR, {}: image and mask must be of the same size'.format(imgList[i]))\n",
    "            continue\n",
    "            \n",
    "        # label the mask into connected regions\n",
    "        lesion_labels,num_lesions = label(msk_V,return_num=True)\n",
    "        lesion_props = regionprops(lesion_labels)\n",
    "\n",
    "        # track lesion number\n",
    "        lesion_count = 0\n",
    "        \n",
    "        # for every lesion in the mask\n",
    "        for obj in lesion_props:\n",
    "            \n",
    "            usubjid.append(patient_id)\n",
    "            timepoint.append(time_id)\n",
    "            trial_arm.append(key.loc[key['USUBJID'] == int(patient_id),'ARM'].item())\n",
    "            lesion_index.append(lesion_count)\n",
    "            lesion_count += 1\n",
    "            \n",
    "            # create the sub-volume of interest within the CT volume\n",
    "            cyl_subV,img_subV,msk_subV,R = createSubVolumesClinical(img_V,img_d,msk_V,obj)\n",
    "            \n",
    "            # calculate threshold using EM\n",
    "            threshold = determineThreshold(img_subV,cyl_subV)\n",
    "\n",
    "            binary_img = np.logical_and(np.logical_and(img_subV > threshold,img_subV > -850),img_subV < 200)\n",
    "            binary_img[~msk_subV] = False\n",
    "            binary_img_centroid = closing(opening(binary_img,ball(radius=int(0.1*R))),ball(radius=int(0.1*R)))\n",
    "            avg_intensity = np.mean(img_subV[binary_img])\n",
    "            mean_intensities.append(avg_intensity)\n",
    "            \n",
    "            # label the cylinder sub-volume into connected regions\n",
    "            cyl_subV_labels = label(cyl_subV)\n",
    "            cyl_subV_props = regionprops(cyl_subV_labels)\n",
    "\n",
    "            # coordinates for the user-defined lesion centroid\n",
    "            cyl_j,cyl_i,cyl_k = [round(i) for i in cyl_subV_props[0].centroid]\n",
    "            \n",
    "            # construct a marker image for the watershed\n",
    "            marker_image = np.zeros((img_subV.shape[0],img_subV.shape[1],img_subV.shape[2]),dtype=np.uint8)\n",
    "            marker_image[~binary_img] = 2         # background/lung parenchyma voxels\n",
    "            marker_image[cyl_j,cyl_i,cyl_k] = 1   # user-defined lesion centroid\n",
    "\n",
    "            # denoise image sub-volume\n",
    "            denoised = gaussian(img_subV,multichannel=False)\n",
    "\n",
    "            # try some funky stuff\n",
    "            max_image = dilation(denoised,ball(2))\n",
    "            min_image = erosion(denoised,ball(2))\n",
    "\n",
    "            gradient_image = max_image - min_image\n",
    "            gradient_image[~msk_subV] = np.min(gradient_image)\n",
    "            \n",
    "            mean_intensities_gradient.append(np.mean(gradient_image[binary_img]))\n",
    "            ent_gradient = entropy(gradient_image[binary_img])\n",
    "            entropy_gradient.append(ent_gradient)\n",
    "            \n",
    "#             if avg_intensity < -150: #np.logical_or(ent_gradient<3,ent_gradient>9):\n",
    "#                 gradient_image = 1 - gradient_image\n",
    "#                 gradient_image = 1 - (gradient_image - np.min(gradient_image))/(np.max(gradient_image)-np.min(gradient_image))\n",
    "                \n",
    "    \n",
    "            # create distance matrix for the 3D bowl function\n",
    "            row,col,slc = np.meshgrid(range(gradient_image.shape[0]),range(gradient_image.shape[1]),range(gradient_image.shape[2]))\n",
    "            dist_matrix = np.sqrt((round(cyl_j) - row)**2 + (round(cyl_i) - col)**2 + ((round(cyl_k) - slc) * float(msk_d['slice_thickness']))**2)\n",
    "            dist_matrix[dist_matrix>=R] = R\n",
    "            dist_matrix = dist_matrix / R\n",
    "            \n",
    "            # modify the gradient image for watershed\n",
    "            mod_gradient = gradient_image * dist_matrix\n",
    "            \n",
    "            # perform watershed segmentation\n",
    "            water_initial = ~watershed(gradient_image,marker_image,connectivity=2)\n",
    "            water_initial_mod = ~watershed(mod_gradient, marker_image,connectivity=2)\n",
    "            \n",
    "            # label the watershed mask into connected regions\n",
    "            water_labels = label(water_initial_mod,background = np.min(water_initial_mod))\n",
    "            water_props = regionprops(water_labels)\n",
    "            \n",
    "            # find the smallest region\n",
    "            water_areas = [water_props[i].area for i in range(len(water_props))]\n",
    "            ind = np.where(water_areas == np.min(water_areas))\n",
    "\n",
    "            # create the mask\n",
    "            water_mask = water_labels == water_props[ind[0][0]].label\n",
    "\n",
    "#             equiv_R = round(water_props[ind[0][0]].equivalent_diameter * 0.15)\n",
    "\n",
    "#             water_mask_open = binary_opening(water_mask,ball(radius = equiv_R))\n",
    "            \n",
    "            # FINALLY this initial segmentation is fed into the active contours function for further refinement\n",
    "            refined_mask = gac(igg(img_subV), iterations = 1, init_level_set=water_mask, threshold = 0.5)\n",
    "            \n",
    "            # fill any holes in the final mask result (unlikely, but you never know)\n",
    "            refined_mask = binary_fill_holes(refined_mask)\n",
    "\n",
    "            IoU_water.append(np.count_nonzero(np.logical_and(water_mask,msk_subV)) / np.count_nonzero(np.logical_or(water_mask,msk_subV)))\n",
    "            IoU_actC.append(np.count_nonzero(np.logical_and(refined_mask,msk_subV)) / np.count_nonzero(np.logical_or(refined_mask,msk_subV)))\n",
    "            IoU_backW.append(np.count_nonzero(np.logical_and(~water_mask,~msk_subV)) / np.count_nonzero(np.logical_or(~water_mask,~msk_subV)))\n",
    "            IoU_backA.append(np.count_nonzero(np.logical_and(~refined_mask,~msk_subV)) / np.count_nonzero(np.logical_or(~refined_mask,~msk_subV)))\n",
    "            \n",
    "            dice_water.append(np.sum(water_mask[msk_subV==True])*2.0 / (np.sum(water_mask) + np.sum(msk_subV)))\n",
    "            dice_actC.append(np.sum(refined_mask[msk_subV==True])*2.0 / (np.sum(refined_mask) + np.sum(msk_subV)))\n",
    "#         # calculate the patient-specific IoU\n",
    "#         all_backIoU.append(np.count_nonzero(np.logical_and(~water_whole,~msk_V))/np.count_nonzero(np.logical_or(~water_whole,~msk_V)))\n",
    "\n",
    "        \n",
    "    return IoU_water,IoU_actC,IoU_backW,IoU_backA,num_lesions_per_patient,patient_index,mean_intensities,mean_intensities_gradient,entropy_gradient,dice_water,dice_actC\n",
    "        \n",
    "\n",
    "# run the pipeline\n",
    "IoU_water,IoU_actC,IoU_backW,IoU_backA,num_lesions_per_patient,patient_index,mean_intensities,mean_intensities_gradient,entropy_gradient,dice_water,dice_actC = segPipeline(all_images,all_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_IoU_AC = (np.array(IoU_actC) + np.array(IoU_backA))/2\n",
    "np.mean(all_IoU_AC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_IoU_WS = (np.array(IoU_water) + np.array(IoU_backW))/2\n",
    "np.mean(all_IoU_WS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "pearsonr(mean_intensities,IoU_actC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(all_IoU_WS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(entropy_gradient,all_IoU_WS)\n",
    "plt.xlabel('Avg. Intensity of Voxels > Bayesian Threshold')\n",
    "plt.ylabel('Avg. IoU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALTERNATIVE EVALUATION METRIC : DICE COEFFICIENT\n",
    "# seg = water_mask\n",
    "# dice = np.sum(seg[msk_subV_true==True])*2.0 / (np.sum(seg) + np.sum(msk_subV_true))\n",
    "# dice\n",
    "mean_intensities_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(entropy_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(entropy_gradient) - 2 * np.std(entropy_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HU = []\n",
    "for i in range(len(dice_water)):\n",
    "    if dice_water[i]<0.5:\n",
    "        HU.append(mean_intensities[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
